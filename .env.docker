# Docker Environment Configuration for Tallman Chat

# Backend Service Configuration
PORT=3231
BACKEND_SERVICE_HOST=localhost
BACKEND_SERVICE_PORT=3231

# LDAP Configuration (adjust for your Docker network)
LDAP_SERVICE_HOST=host.docker.internal
LDAP_SERVICE_PORT=3100

# Ollama Configuration (Docker container networking)
OLLAMA_HOST=host.docker.internal:12434
OLLAMA_MODEL=ibm-granite_granite-4.0-h-tiny

# Secondary LLM Configuration (OpenAI-compatible) - Docker Granite API bridge
SECONDARY_LLM_BASE_URL=http://host.docker.internal:12435/v1
SECONDARY_LLM_MODEL=granite-4.0-nano

# Primary LLM Configuration (Google Gemini)
GEMINI_API_KEY=AIzaSyDLbTa3Y_zZuwQ6uvD3Cqg3HvO9UGB-iIY
GEMINI_MODEL=gemini-2.0-flash-exp

# Node Environment
NODE_ENV=production

# Server Configuration
UI_PORT=3230

# Backdoor Authentication (for testing only)
BACKDOOR_USERNAME=robertstar@aol.com
BACKDOOR_PASSWORD=Rm2214ri#
