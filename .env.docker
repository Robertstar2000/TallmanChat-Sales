# Docker Environment Configuration for Tallman Chat

# Backend Service Configuration
PORT=3231
BACKEND_SERVICE_HOST=localhost
BACKEND_SERVICE_PORT=3231

# LDAP Configuration (adjust for your Docker network)
LDAP_SERVICE_HOST=host.docker.internal
LDAP_SERVICE_PORT=3100

# Ollama Configuration (Docker container networking)
OLLAMA_HOST=host.docker.internal:12434
OLLAMA_MODEL=ibm-granite_granite-4.0-h-tiny

# Secondary LLM Configuration (OpenAI-compatible) - LocalAI with Granite model
SECONDARY_LLM_BASE_URL=http://host.docker.internal:8080
SECONDARY_LLM_MODEL=ibm-granite_granite-4.0-h-tiny

# Tertiary LLM Configuration (Google Gemini)
GEMINI_API_KEY=AIzaSyDFAnryu6QsY6IgyHZMiiKBNSkJdPp88Bg
GEMINI_MODEL=gemini-1.5-flash

# Node Environment
NODE_ENV=production

# Server Configuration
UI_PORT=3230

# Backdoor Authentication (for testing only)
BACKDOOR_USERNAME=robertstar@aol.com
BACKDOOR_PASSWORD=Rm2214ri#
